

Skip to main content


Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.





Advertisement























View all journals




Search




My Account


Login













Explore content




About the journal




Publish with us






Subscribe







Sign up for alerts




RSS feed










nature



news




article













NEWS
23 December 2020
Correction 23 December 2020

Prestigious AI meeting takes steps to improve ethics of research


                    For the first time, the organizers of NeurIPS required speakers to consider the societal impact of their work.
                




Davide Castelvecchi





Davide Castelvecchi


View author publications

You can also search for this author in PubMed
 Google Scholar












Twitter





Facebook





Email









You have full access to this article via your institution.


Download PDF









Download PDF












Artificial-intelligence research is coming under increasing ethical scrutiny.Credit: Michael Cohen/Getty


After a year of heavy scrutiny and seemingly endless controversy around artificial-intelligence (AI) technologies, the field’s most prestigious conference has tried to set a good example. For the first time, the Neural Information Processing Systems (NeurIPS) meeting, which took place completely online this month, required presenters to submit a statement on the broader impact their research could have on society, including any possible negative effects.The organizers also appointed a panel of reviewers to scrutinize papers that raised ethical concerns — a process that could lead to their rejection.“I think there’s a lot of value even in getting people to think about these things,” says Jack Poulson, founder of the industry watchdog Tech Inquiry in Toronto, Canada. He adds that the policy could help to shift culture in the field.Researchers who work on machine learning are increasingly aware of the challenges posed by harmful uses of the technology, from the creation of falsified videos, or ‘deepfakes’, to mistakes by police who rely on facial-recognition algorithms in deciding who to arrest.“There was previously a period of techno optimism,” says Iason Gabriel, an ethicist at the AI powerhouse DeepMind, a sister company of Google based in London. “Clearly, that has changed in recent years.”Unintended usesThe idea of conference participants writing an impact statement was inspired by the Future of Computing Academy, a group led by Brent Hecht, a specialist in the human impacts of technology at Microsoft and at Northwestern University in Evanston, Illinois. In 2018, Hecht and his collaborators proposed that computer-science publications be required to state the potential side effects and unintended uses of their research. Unlike in other scientific disciplines, most peer review in computer science happens when manuscripts are submitted to conferences, rather than to scholarly journals. As the field’s largest and most prestigious conference, NeurIPS was a natural choice to test this proposal.This year’s conference attracted 9,467 paper submissions. The reviewers assessed submissions mainly on their scientific value, but papers with potential to be accepted could be flagged for a full review by a separate ethics committee led by Gabriel. Of 290 papers that were flagged, 4 were ultimately rejected by the programme chairs because of ethical considerations, says Marc’Aurelio Ranzato, a computer scientist at Facebook AI Research in New York City who was one of the conference’s programme chairs.“In general, I would say the ethics process has done well,” says Katherine Heller, a computer scientist at Google in Mountain View, California, who was the conference’s co-chair of diversity and inclusion.Gabriel says that most problematic issues should have been caught, because any of the three anonymous peer reviewers could flag a paper, as could the subject-area chair. “A signal from any one of them would be enough to engage the review process,” he says. Still, he admits that the process was not infallible. For example, if all the reviewers happened to be men — not unusual in a male-dominated field — they might not be able to adequately assess whether an algorithm could affect women negatively. “I can’t rule out the possibility that there would be blind spots of this kind,” Gabriel says.In addition, reviewers were not given specific guidance on what constitutes harm to society. For example, says Ranzato, some reviewers flagged papers that made use of databases containing personal information or photographs that were collected without explicit consent. The use of such databases has come under heavy criticism, but the conference organizers did not single out this issue to reviewers or provide a list of problematic databases. Still, Ranzato adds that the review policy is a step in the right direction. “Nothing is perfect, but it’s better than before.”Policing AIThe last day of the conference featured a special session focused on the broader impact of AI on society. Hecht, Gabriel and other panellists discussed ways to address the industry’s problems. Hanna Wallach, a researcher at Microsoft in New York City, called for researchers to assess and mitigate any potential harm to society from the early stages of research, without assuming that their colleagues who develop and market end products will do that ethical work. Ethical thinking should be built into the machine-learning field rather than simply being outsourced to ethics specialists, she said, otherwise, “other disciplines could become the police while programmers try to evade them”.Wallach and others, such as Donald Martin, a technical programme manager at Google in San Francisco, California, are working to redesign the product-development process at their companies so that it incorporates awareness of social context. AI ethics, Martin says, “is not a crisis in the public understanding of science, but a crisis in science’s understanding of the public”.The revamped review process and the ethics-focused discussions are the latest in a series of efforts by NeurIPS organizers to improve practices in machine learning and AI. In 2018, the conference dropped an acronym that many people found offensive, and began a crackdown on sexist behaviour by participants. And last year’s meeting featured robust discussions of AI ethics and inclusivity.The mood of this year’s conference was affected by events that occurred on its eve. On 2 December, Timnit Gebru, a leading researcher on racial bias in machine-learning algorithms, said that after a dispute over the publication of a paper she had co-authored, she had been dismissed from Google, where she co-led a team working on ethics in AI. Google has stated that it accepted her resignation; Gebru has said that she never resigned, but had merely threatened to do so at a later date if her conditions on the paper’s internal review were not met.The situation has led many researchers to publicly question Google’s commitment to ethical AI. Thousands both at Google and elsewhere have signed a letter of solidarity, pointing out that Gebru was “one of very few Black women Research Scientists at the company, which boasts a dismal 1.6% Black women employees overall”.On 16 December, members of the US Congress wrote to Google chief executive Sundar Pichai, saying that “the incident raises broader questions, the answers to which may meaningfully impact our work as legislators”. Google did not respond to a request for comment from Nature’s news team.

Nature 589, 12-13 (2021)
doi: https://doi.org/10.1038/d41586-020-03611-8

Updates & Corrections

Correction 23 December 2020: This story was updated to clarify that the ethics committee didn't have the power to reject a submission. It was the programme chairs who ultimately rejected submissions because of ethical considerations.





Related Articles





                        
                        The battle for ethical AI at the world’s biggest machine-learning conference
                    





                        
                        How one conference embraced diversity
                    






                        
                        Is facial recognition too biased to be let loose?
                    






                        
                        The ethical questions that haunt facial-recognition research
                    





                        
                        AI conference widely known as ‘NIPS’ changes its controversial acronym
                    



Subjects


Machine learning


Ethics


Technology




Latest on:


Machine learning





Gran Turismo champion, reimagined urine — the week in infographics
News 15 FEB 22





Neural networks overtake humans in Gran Turismo racing game
News & Views 09 FEB 22





Early prediction of preeclampsia in pregnancy with cell-free RNA
Article 09 FEB 22






Ethics





How to protect the first ‘CRISPR babies’ prompts ethical debate
News 25 FEB 22





An engineer advances fire-management laws in Colombia
Career Q&A 23 FEB 22





Neuroscience saved my life and gave me a vocation
Career Q&A 23 FEB 22






Technology





Space junk heading for Moon will add to 60+ years of lunar debris
News 28 FEB 22





From the archive
News & Views 15 FEB 22





Robots rise to meet the challenge of caring for old people
Outlook 19 JAN 22

















                Jobs
                







                                Postdoctoral Research Scientist
                            


Albert Einstein College of Medicine (Einstein)
Bronx, NY, United States





                                Scientist/ Senior Scientist
                            


Genentech, Inc.
South San Francisco, CA, United States





                                ASSOCIATE DEAN OF RESEARCH
                            


Lawrence Technological University (LTU)
SOUTHFIELD, MI, MI, United States





                                Postdoc Fellow
                            


Harvard Medical School (HMS), Massachusetts General Hospital, United States
Multiple locations










You have full access to this article via your institution.


Download PDF









Download PDF




Related Articles





                        
                        The battle for ethical AI at the world’s biggest machine-learning conference
                    





                        
                        How one conference embraced diversity
                    






                        
                        Is facial recognition too biased to be let loose?
                    






                        
                        The ethical questions that haunt facial-recognition research
                    





                        
                        AI conference widely known as ‘NIPS’ changes its controversial acronym
                    



Subjects


Machine learning


Ethics


Technology












Sign up to Nature Briefing
An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.




Email address



Yes! Sign me up to receive the daily Nature Briefing email. I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.

Sign up



















Close banner






Close






Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.





Email address


Sign up



I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.











Close banner






Close



Get the most important science stories of the day, free in your inbox.
Sign up for Nature Briefing
            









Explore content



                                    Research articles
                                



                                    News
                                



                                    Opinion
                                



                                    Research Analysis
                                



                                    Careers
                                



                                    Books & Culture
                                



                                    Podcasts
                                



                                    Videos
                                



                                    Current issue
                                



                                    Browse issues
                                



                                    Collections
                                



                                    Subjects
                                


Follow us on Facebook
                            


Follow us on Twitter
                            



Subscribe



Sign up for alerts




RSS feed







About the journal



                                Journal Staff
                            



                                About the Editors
                            



                                Journal Information
                            



                                Our publishing models
                            



                                Editorial Values Statement
                            



                                Journal Impact
                            



                                Awards
                            



                                Contact
                            



                                Editorial policies
                            



                                History of Nature
                            



                                Send a news tip
                            






Publish with us



                                For Authors
                            



                                For Referees
                            


Submit manuscript







Search



Search articles by subject, keyword or author





Show results from

All journals



Search








                    Advanced search
                


Quick links

Explore articles by subject
Find a job
Guide to authors
Editorial policies










                    Nature (Nature)
                

ISSN 1476-4687 (online)
    

ISSN 0028-0836 (print)
    








nature.com sitemap





About us
Press releases
Press office
Contact us





















Discover content

Journals A-Z
Articles by subject
Nano
Protocol Exchange
Nature Index



Publishing policies

Nature portfolio policies
Open access



Author & Researcher services

Reprints & permissions
Research data
Language editing
Scientific editing
Nature Masterclasses
Nature Research Academies



Libraries & institutions

Librarian service & tools
Librarian portal
Open research
Recommend to library



Advertising & partnerships

Advertising
Partnerships & Services
Media kits
Branded content



Career development

Nature Careers
Nature  Conferences
Nature  events



Regional websites

Nature Africa
Nature China
Nature India
Nature Italy
Nature Japan
Nature Korea
Nature Middle East



Legal & Privacy

Privacy Policy
Use of cookies
Manage cookies/Do not sell my data
Legal notice
Accessibility statement
Terms & Conditions
California Privacy Statement










© 2022 Springer Nature Limited















































